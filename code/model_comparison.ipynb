{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02441f81",
   "metadata": {},
   "source": [
    "1. [x] load data from condition 1 to 3 in experiment 1\n",
    "2. [x] Get PARSER and rational chunker to learn from this data\n",
    "3. [x] Compute correlation and similarity measure on top of the results\n",
    "4. [x] Look for best fitting parameter for rational chunker, PARSER and associative learner\n",
    "\n",
    "\n",
    "rational chunker parameters: w and nit: learn_sequence(w = 0, nit = 4)\n",
    "\n",
    "PARSER parameters: forgetting_decrement, percept_increment: PARSER(speech, forgetting_decrement = 0.05, percept_increment = 0.5)\n",
    "\n",
    "associative learning components: theta: associative_learning(seq, theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97de09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open('../data/modelcomparison.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfabbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.10]#[0.1,0.2,0.3,0.4,0.5,0.6]\n",
    "forgetting_decrements = [0.06,0.07,0.08]\n",
    "percept_increment = [0.5,0.7,1.0]\n",
    "thetas = [0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f8fec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PARSER import *\n",
    "from utils import *\n",
    "from associative_learning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj  2\n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "subj  4\n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "subj  6\n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "subj  8\n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "Final Percept Shaper (with chunk weights): \n",
      "subj  9\n"
     ]
    }
   ],
   "source": [
    "dfsubject = pd.read_csv('../Data/filtered_exp1.csv')\n",
    "\n",
    "data = {}\n",
    "data['id'] = []\n",
    "\n",
    "for w in ws: \n",
    "    name = 'rational_chunking_p w = ' + str(w)\n",
    "    data[name] = []\n",
    "    name = 'rational_chunking_rt w = ' + str(w)\n",
    "    data[name] = []\n",
    "    \n",
    "    \n",
    "for fd in forgetting_decrements:\n",
    "    for pi in percept_increment:   \n",
    "        name = 'parser_p forgetting_decrement = ' + str(fd) + ' percept_increment = ' + str(pi)\n",
    "        data[name] = []\n",
    "        name = 'parser_log_p forgetting_decrement = ' + str(fd) + ' percept_increment = ' + str(pi)\n",
    "        data[name] = []\n",
    "\n",
    "\n",
    "\n",
    "for theta in thetas:\n",
    "    name = 'associative_learner_p theta = ' + str(theta)\n",
    "    data[name] = []\n",
    "    name = 'associative_learning_log_p theta = ' + str(theta)\n",
    "    data[name] = []\n",
    "\n",
    "\n",
    "data['seq'] = []\n",
    "data['cond'] = []\n",
    "data['subject_rt'] = []\n",
    "\n",
    "\n",
    "for cond in [0,1,2]:\n",
    "    for subj in np.unique(dfsubject[dfsubject['condition'] == cond]['id']):\n",
    "        print('subj ', subj)\n",
    "        \n",
    "        subseq = []\n",
    "        for press in list(dfsubject[dfsubject['id'] == subj]['userpress']):\n",
    "            if press == list(dfsubject[dfsubject['id'] == subj]['keyassignment'])[0][2]:\n",
    "                subseq.append(1)\n",
    "            if press == list(dfsubject[dfsubject['id'] == subj]['keyassignment'])[0][7]:\n",
    "                subseq.append(2)\n",
    "            if press == list(dfsubject[dfsubject['id'] == subj]['keyassignment'])[0][12]:\n",
    "                subseq.append(3)\n",
    "            if press == list(dfsubject[dfsubject['id'] == subj]['keyassignment'])[0][17]:\n",
    "                subseq.append(4)\n",
    "        seq = subseq[:800]\n",
    "        \n",
    "        # only record data during training \n",
    "        data['id'] += [subj]*600\n",
    "        data['subject_rt'] += list(dfsubject[dfsubject['id'] == subj]['timecollect'])[200:800]\n",
    "        data['seq'] += seq[200:]\n",
    "        data['cond'] += [cond]*600\n",
    "\n",
    "        ########## Use rational chunking model to learn from chunks ###########\n",
    "        # store learned data like list of tuples \n",
    "        \n",
    "        \n",
    "        for this_w in ws: \n",
    "\n",
    "            this_sequence = seq\n",
    "            i = 200\n",
    "            step = 10\n",
    "            precord = []\n",
    "            rtrecord = []\n",
    "            # go through the sequence 10 units at a time\n",
    "            while i<=800:    \n",
    "                M,T,bagofchunk,rt,correctness,cp,reacted_press  = learn_sequence(this_sequence[0:i], Print = False, w = this_w)\n",
    "                correctness, rt, choice_probability,reacted_press,this_M, this_T = partition_seq_hastily(this_sequence,bagofchunk)\n",
    "                rtrecord = rtrecord + rt[i:i+step]\n",
    "                precord = precord + choice_probability[i:i+step]\n",
    "                i = i + step\n",
    "            \n",
    "            data['rational_chunking_p w = ' + str(this_w)] += precord\n",
    "            data['rational_chunking_rt w = ' + str(this_w)] += rtrecord\n",
    "        \n",
    "\n",
    "        \n",
    "        for fd in forgetting_decrements:\n",
    "            for pi in percept_increment:   \n",
    "                name = 'parser_p forgetting_decrement = ' + str(fd) + ' percept_increment = ' + str(pi)\n",
    "                # parse sequence based on the learned chunks\n",
    "                # generate probability evaluation based on chunk record\n",
    "                p_parser = PARSER_probability(seq[200:800],forgetting_decrement = fd, percept_increment = pi)\n",
    "                data[name] += p_parser\n",
    "                neglogp = list(-np.log(p_parser))\n",
    "                name = 'parser_log_p forgetting_decrement = ' + str(fd) + ' percept_increment = ' + str(pi)\n",
    "                data[name] +=neglogp\n",
    "\n",
    "        for theta in thetas:            \n",
    "            name = 'associative_learner_p theta = ' + str(theta)\n",
    "            p_associative_learning = associative_learning(seq[200:800],theta = theta)\n",
    "            data[name] += p_associative_learning\n",
    "\n",
    "            neglogp = list(-np.log(p_associative_learning))\n",
    "            name = 'associative_learning_log_p theta = ' + str(theta)\n",
    "            data[name] += neglogp\n",
    "\n",
    "\n",
    "        with open('../data/modelcomparisonfinegrained.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "            \n",
    "            \n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.to_csv('../data/modelcomparisonfinegrained.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acca72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import spearmanr\n",
    "import math \n",
    "dfchunking = {}# model comparison dataframe\n",
    "dfchunking['condition'] = []\n",
    "dfchunking['parameter'] = []\n",
    "dfchunking['spearmanr'] = []\n",
    "dfchunking['id'] = []\n",
    "\n",
    "\n",
    "dfparser = {}\n",
    "dfparser['condition'] = []\n",
    "dfparser['forgetting decrement'] = []\n",
    "dfparser['percept increment'] = []\n",
    "dfparser['spearmanr'] = []\n",
    "dfparser['id'] = []\n",
    "\n",
    "dfal = {}\n",
    "dfal['condition'] = []\n",
    "dfal['parameter'] = []\n",
    "dfal['spearmanr'] = []\n",
    "dfal['id'] = []\n",
    "\n",
    "for cond in [0,1,2]:\n",
    "    for ID in np.unique(dfsubject[dfsubject['condition'] == cond]['id']):\n",
    "        rt_subj = list(df[(df['id'] == ID) & (df['subject_rt'] <=1000) & (df['cond'] == cond)]['subject_rt'])\n",
    "        \n",
    "        for w in ws: \n",
    "            name = 'rational_chunking_rt w = ' + str(w)            \n",
    "            rt_rationalmodel = df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)][name]\n",
    "            corr_rational_chunking, p_rational_chunking = spearmanr(rt_subj, rt_rationalmodel,nan_policy = 'omit')\n",
    "            dfchunking['condition'].append(cond)\n",
    "            dfchunking['parameter'].append(w)\n",
    "            dfchunking['spearmanr'].append(corr_rational_chunking)\n",
    "            dfchunking['id'].append(ID)\n",
    "            \n",
    "        for fd in forgetting_decrements:\n",
    "            for pi in percept_increment:   \n",
    "                name = 'parser_log_p forgetting_decrement = ' + str(fd) + ' percept_increment = ' + str(pi)\n",
    "                rt_parser = df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)][name]\n",
    "                corr_parser, p_parser = spearmanr(rt_subj, rt_parser,nan_policy = 'omit')\n",
    "                dfparser['condition'].append(cond)\n",
    "                dfparser['forgetting decrement'].append(fd)\n",
    "                dfparser['percept increment'].append(pi)\n",
    "                dfparser['id'].append(ID)\n",
    "                dfparser['spearmanr'].append(corr_parser)\n",
    "                \n",
    "                \n",
    "        for theta in thetas:\n",
    "            name = 'associative_learning_log_p theta = ' + str(theta)\n",
    "            rt_associative_learning = df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)][name]\n",
    "            corr_associative_learning, p_associative_learning = spearmanr(rt_associative_learning, rt_subj, nan_policy = 'omit')\n",
    "            dfal['condition'].append(cond)\n",
    "            dfal['parameter'].append(theta)\n",
    "            dfal['spearmanr'].append(corr_associative_learning)\n",
    "            dfal['id'].append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa2c7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchunking = pd.DataFrame.from_dict(dfchunking)\n",
    "dfparser = pd.DataFrame.from_dict(dfparser)\n",
    "dfal = pd.DataFrame.from_dict(dfal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54e6cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =  0.1\n",
      "rational chunking correlation: 0.206\n",
      "w =  0.2\n",
      "rational chunking correlation: 0.203\n",
      "w =  0.3\n",
      "rational chunking correlation: 0.184\n",
      "w =  0.4\n",
      "rational chunking correlation: 0.151\n",
      "w =  0.5\n",
      "rational chunking correlation: 0.133\n",
      "w =  0.6\n",
      "rational chunking correlation: 0.116\n",
      "pi =  0.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.100\n",
      "pi =  1.0\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.088\n",
      "pi =  1.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.097\n",
      "pi =  0.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.083\n",
      "pi =  1.0\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.076\n",
      "pi =  1.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.085\n",
      "pi =  0.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.085\n",
      "pi =  1.0\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.086\n",
      "pi =  1.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.099\n",
      "pi =  0.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.078\n",
      "pi =  1.0\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.107\n",
      "pi =  1.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.093\n",
      "pi =  0.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.101\n",
      "pi =  1.0\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.077\n",
      "pi =  1.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.089\n",
      "theta =  0.7\n",
      "associative learning correlation: 0.136\n",
      "theta =  0.8\n",
      "associative learning correlation: 0.161\n",
      "theta =  0.9\n",
      "associative learning correlation: 0.190\n",
      "theta =  1\n",
      "associative learning correlation: 0.223\n"
     ]
    }
   ],
   "source": [
    "for w in ws: \n",
    "    print('w = ',w)\n",
    "    print('rational chunking correlation: %.3f' % (np.mean(dfchunking[(dfchunking['parameter'] == w)]['spearmanr'])))\n",
    "\n",
    "for fd in forgetting_decrements:\n",
    "    for pi in percept_increment:  \n",
    "        print('pi = ', pi)\n",
    "        print('fd = ', fd)\n",
    "        print('PARSER correlation: %.3f' % (np.mean(dfparser[(dfparser['forgetting decrement'] == fd) & (dfparser['percept increment'] == pi) ]['spearmanr'])))\n",
    "\n",
    "for theta in thetas:\n",
    "    print('theta = ', theta)\n",
    "    print('associative learning correlation: %.3f' % (np.mean(dfal[(dfal['parameter'] == theta)]['spearmanr'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28b9f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition =  0\n",
      "w =  0.1\n",
      "rational chunking correlation: 0.054\n",
      "w =  0.2\n",
      "rational chunking correlation: 0.050\n",
      "w =  0.3\n",
      "rational chunking correlation: 0.027\n",
      "w =  0.4\n",
      "rational chunking correlation: 0.006\n",
      "w =  0.5\n",
      "rational chunking correlation: 0.004\n",
      "w =  0.6\n",
      "rational chunking correlation: 0.008\n",
      "pi =  0.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.014\n",
      "pi =  1.0\n",
      "fd =  0.03\n",
      "PARSER correlation: -0.005\n",
      "pi =  1.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.024\n",
      "pi =  0.5\n",
      "fd =  0.04\n",
      "PARSER correlation: -0.002\n",
      "pi =  1.0\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.010\n",
      "pi =  1.5\n",
      "fd =  0.04\n",
      "PARSER correlation: -0.009\n",
      "pi =  0.5\n",
      "fd =  0.05\n",
      "PARSER correlation: -0.010\n",
      "pi =  1.0\n",
      "fd =  0.05\n",
      "PARSER correlation: -0.002\n",
      "pi =  1.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.008\n",
      "pi =  0.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.010\n",
      "pi =  1.0\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.011\n",
      "pi =  1.5\n",
      "fd =  0.06\n",
      "PARSER correlation: -0.002\n",
      "pi =  0.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.026\n",
      "pi =  1.0\n",
      "fd =  0.07\n",
      "PARSER correlation: -0.008\n",
      "pi =  1.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.004\n",
      "theta =  0.7\n",
      "associative learning correlation: 0.069\n",
      "theta =  0.8\n",
      "associative learning correlation: 0.078\n",
      "theta =  0.9\n",
      "associative learning correlation: 0.086\n",
      "theta =  1\n",
      "associative learning correlation: 0.092\n",
      "condition =  1\n",
      "w =  0.1\n",
      "rational chunking correlation: 0.294\n",
      "w =  0.2\n",
      "rational chunking correlation: 0.288\n",
      "w =  0.3\n",
      "rational chunking correlation: 0.277\n",
      "w =  0.4\n",
      "rational chunking correlation: 0.262\n",
      "w =  0.5\n",
      "rational chunking correlation: 0.244\n",
      "w =  0.6\n",
      "rational chunking correlation: 0.215\n",
      "pi =  0.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.128\n",
      "pi =  1.0\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.123\n",
      "pi =  1.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.117\n",
      "pi =  0.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.111\n",
      "pi =  1.0\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.073\n",
      "pi =  1.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.121\n",
      "pi =  0.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.102\n",
      "pi =  1.0\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.105\n",
      "pi =  1.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.141\n",
      "pi =  0.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.072\n",
      "pi =  1.0\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.149\n",
      "pi =  1.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.139\n",
      "pi =  0.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.102\n",
      "pi =  1.0\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.095\n",
      "pi =  1.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.109\n",
      "theta =  0.7\n",
      "associative learning correlation: 0.149\n",
      "theta =  0.8\n",
      "associative learning correlation: 0.191\n",
      "theta =  0.9\n",
      "associative learning correlation: 0.238\n",
      "theta =  1\n",
      "associative learning correlation: 0.295\n",
      "condition =  2\n",
      "w =  0.1\n",
      "rational chunking correlation: 0.259\n",
      "w =  0.2\n",
      "rational chunking correlation: 0.258\n",
      "w =  0.3\n",
      "rational chunking correlation: 0.233\n",
      "w =  0.4\n",
      "rational chunking correlation: 0.172\n",
      "w =  0.5\n",
      "rational chunking correlation: 0.138\n",
      "w =  0.6\n",
      "rational chunking correlation: 0.113\n",
      "pi =  0.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.153\n",
      "pi =  1.0\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.140\n",
      "pi =  1.5\n",
      "fd =  0.03\n",
      "PARSER correlation: 0.144\n",
      "pi =  0.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.135\n",
      "pi =  1.0\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.142\n",
      "pi =  1.5\n",
      "fd =  0.04\n",
      "PARSER correlation: 0.138\n",
      "pi =  0.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.157\n",
      "pi =  1.0\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.151\n",
      "pi =  1.5\n",
      "fd =  0.05\n",
      "PARSER correlation: 0.141\n",
      "pi =  0.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.150\n",
      "pi =  1.0\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.155\n",
      "pi =  1.5\n",
      "fd =  0.06\n",
      "PARSER correlation: 0.134\n",
      "pi =  0.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.172\n",
      "pi =  1.0\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.139\n",
      "pi =  1.5\n",
      "fd =  0.07\n",
      "PARSER correlation: 0.150\n",
      "theta =  0.7\n",
      "associative learning correlation: 0.184\n",
      "theta =  0.8\n",
      "associative learning correlation: 0.208\n",
      "theta =  0.9\n",
      "associative learning correlation: 0.237\n",
      "theta =  1\n",
      "associative learning correlation: 0.273\n"
     ]
    }
   ],
   "source": [
    "for cond in [0,1,2]:\n",
    "    print('condition = ', cond)\n",
    "    for w in ws: \n",
    "        print('w = ',w)\n",
    "        print('rational chunking correlation: %.3f' % (np.mean(dfchunking[(dfchunking['parameter'] == w) & (dfchunking['condition'] == cond)]['spearmanr'])))\n",
    "\n",
    "    for fd in forgetting_decrements:\n",
    "        for pi in percept_increment:  \n",
    "            print('pi = ', pi)\n",
    "            print('fd = ', fd)\n",
    "            print('PARSER correlation: %.3f' % (np.mean(dfparser[(dfparser['condition'] == cond) & (dfparser['forgetting decrement'] == fd) & (dfparser['percept increment'] == pi) ]['spearmanr'])))\n",
    "\n",
    "    for theta in thetas:\n",
    "        print('theta = ', theta)\n",
    "        print('associative learning correlation: %.3f' % (np.mean(dfal[(dfal['condition'] == cond) & (dfal['parameter'] == theta)]['spearmanr'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bab3d6fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rational_chunking_p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rational_chunking_p'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-89e84c2bc17e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfsubject\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'condition'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mrt_rationalmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cond'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_rt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rational_chunking_p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mrt_rationalmodelsim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cond'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_rt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rational_chunking_rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrt_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cond'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_rt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parser_p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rational_chunking_p'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import spearmanr\n",
    "import math \n",
    "# seed random number generator\n",
    "dfrt = {}\n",
    "dfrt['ID'] = []\n",
    "dfrt['rt'] = []\n",
    "dfrt['lgpparser'] = []\n",
    "dfrt['lgprational_chunking'] = []\n",
    "dfrt['sim_rt_rational_chunking'] = []\n",
    "\n",
    "\n",
    "seed(1)\n",
    "c_parser = []\n",
    "lgpparser = []\n",
    "c_rational_chunking = []\n",
    "lgprational_chunking = []\n",
    "\n",
    "c_sim_rational_chunking = []\n",
    "\n",
    "for cond in [0,1,2]:\n",
    "    for ID in np.unique(dfsubject[dfsubject['condition'] == cond]['id']):\n",
    "        rt_rationalmodel = list(-np.log(np.array(df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)]['rational_chunking_p'])))\n",
    "        rt_rationalmodelsim = list(np.array(df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)]['rational_chunking_rt']))\n",
    "        rt_parser = list(-np.log(np.array(df[(df['cond'] == cond) & (df['id'] == ID) & (df['subject_rt'] <=1000)]['parser_p'])))\n",
    "        rt_subj = list(df[(df['id'] == ID) & (df['subject_rt'] <=1000) & (df['cond'] == cond)]['subject_rt'])\n",
    "        \n",
    "        corr_rational_chunking, p_rational_chunking = spearmanr(rt_subj, rt_rationalmodel)\n",
    "        corr_sim_rational_chunking, p_sim_rational_chunking = spearmanr(rt_subj, rt_rationalmodelsim)\n",
    "        corr_parser, p_parser = spearmanr(rt_parser, rt_subj)\n",
    "        \n",
    "        lgpparser += rt_parser\n",
    "        lgprational_chunking += rt_rationalmodel\n",
    "        \n",
    "        dfrt['rt']+=rt_subj\n",
    "        dfrt['ID']+= [ID]*len(rt_subj)\n",
    "        dfrt['lgpparser'] += rt_parser\n",
    "        dfrt['lgprational_chunking'] += rt_rationalmodel\n",
    "        dfrt['sim_rt_rational_chunking'] += rt_rationalmodelsim\n",
    "\n",
    "\n",
    "\n",
    "        if not math.isnan(p_parser):\n",
    "            c_parser.append(corr_parser)\n",
    "        if not math.isnan(p_rational_chunking):\n",
    "            c_rational_chunking.append(corr_rational_chunking)\n",
    "        if not math.isnan(p_sim_rational_chunking):\n",
    "            c_sim_rational_chunking.append(corr_sim_rational_chunking)\n",
    "            \n",
    "dfrt = pd.DataFrame.from_dict(dfrt)\n",
    "\n",
    "dfrt.to_csv('../data/modelcomparison.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f495bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rational_chunking_p w = 0.1</th>\n",
       "      <th>rational_chunking_rt w = 0.1</th>\n",
       "      <th>rational_chunking_p w = 0.2</th>\n",
       "      <th>rational_chunking_rt w = 0.2</th>\n",
       "      <th>rational_chunking_p w = 0.3</th>\n",
       "      <th>rational_chunking_rt w = 0.3</th>\n",
       "      <th>rational_chunking_p w = 0.4</th>\n",
       "      <th>rational_chunking_rt w = 0.4</th>\n",
       "      <th>rational_chunking_p w = 0.5</th>\n",
       "      <th>...</th>\n",
       "      <th>associative_learning_log_p theta = 0.7</th>\n",
       "      <th>associative_learner_p theta = 0.8</th>\n",
       "      <th>associative_learning_log_p theta = 0.8</th>\n",
       "      <th>associative_learner_p theta = 0.9</th>\n",
       "      <th>associative_learning_log_p theta = 0.9</th>\n",
       "      <th>associative_learner_p theta = 1</th>\n",
       "      <th>associative_learning_log_p theta = 1</th>\n",
       "      <th>seq</th>\n",
       "      <th>cond</th>\n",
       "      <th>subject_rt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>5</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>5</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>4</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>5</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>6</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>6</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>6</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>4</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>4</td>\n",
       "      <td>0.345070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.029619</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>4</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>4</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>4</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>4</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85195</th>\n",
       "      <td>142</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>6</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.333331</td>\n",
       "      <td>1.098618</td>\n",
       "      <td>0.332937</td>\n",
       "      <td>1.099802</td>\n",
       "      <td>0.315436</td>\n",
       "      <td>1.153799</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85196</th>\n",
       "      <td>142</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.333331</td>\n",
       "      <td>1.098620</td>\n",
       "      <td>0.332849</td>\n",
       "      <td>1.100065</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>1.160488</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85197</th>\n",
       "      <td>142</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>4</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>...</td>\n",
       "      <td>1.324357</td>\n",
       "      <td>0.278809</td>\n",
       "      <td>1.277229</td>\n",
       "      <td>0.304460</td>\n",
       "      <td>1.189216</td>\n",
       "      <td>0.364341</td>\n",
       "      <td>1.009665</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85198</th>\n",
       "      <td>142</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>5</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>1.098617</td>\n",
       "      <td>0.333007</td>\n",
       "      <td>1.099590</td>\n",
       "      <td>0.317881</td>\n",
       "      <td>1.146079</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85199</th>\n",
       "      <td>142</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>4</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.333338</td>\n",
       "      <td>1.098598</td>\n",
       "      <td>0.334283</td>\n",
       "      <td>1.095767</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.980829</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85200 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  rational_chunking_p w = 0.1  rational_chunking_rt w = 0.1  \\\n",
       "0        2                     1.000000                             4   \n",
       "1        2                     0.349398                             5   \n",
       "2        2                     0.387879                             6   \n",
       "3        2                     0.387879                             4   \n",
       "4        2                     0.385542                             4   \n",
       "...    ...                          ...                           ...   \n",
       "85195  142                     0.474227                             6   \n",
       "85196  142                     0.474227                             5   \n",
       "85197  142                     0.472727                             4   \n",
       "85198  142                     0.474227                             5   \n",
       "85199  142                     0.474227                             4   \n",
       "\n",
       "       rational_chunking_p w = 0.2  rational_chunking_rt w = 0.2  \\\n",
       "0                         1.000000                             5   \n",
       "1                         0.349398                             5   \n",
       "2                         0.387879                             6   \n",
       "3                         0.387879                             5   \n",
       "4                         0.385542                             4   \n",
       "...                            ...                           ...   \n",
       "85195                     0.474227                             5   \n",
       "85196                     0.474227                             5   \n",
       "85197                     0.472727                             4   \n",
       "85198                     0.474227                             5   \n",
       "85199                     0.474227                             4   \n",
       "\n",
       "       rational_chunking_p w = 0.3  rational_chunking_rt w = 0.3  \\\n",
       "0                         1.000000                             4   \n",
       "1                         0.349398                             4   \n",
       "2                         0.387879                             6   \n",
       "3                         0.387879                             5   \n",
       "4                         0.385542                             4   \n",
       "...                            ...                           ...   \n",
       "85195                     0.474227                             5   \n",
       "85196                     0.474227                             5   \n",
       "85197                     0.472727                             4   \n",
       "85198                     0.474227                             5   \n",
       "85199                     0.474227                             4   \n",
       "\n",
       "       rational_chunking_p w = 0.4  rational_chunking_rt w = 0.4  \\\n",
       "0                         1.000000                             4   \n",
       "1                         0.349398                             5   \n",
       "2                         0.387879                             6   \n",
       "3                         0.387879                             4   \n",
       "4                         0.385542                             4   \n",
       "...                            ...                           ...   \n",
       "85195                     0.474227                             5   \n",
       "85196                     0.474227                             5   \n",
       "85197                     0.472727                             4   \n",
       "85198                     0.474227                             5   \n",
       "85199                     0.474227                             4   \n",
       "\n",
       "       rational_chunking_p w = 0.5  ...  \\\n",
       "0                         1.000000  ...   \n",
       "1                         0.357143  ...   \n",
       "2                         1.000000  ...   \n",
       "3                         0.345070  ...   \n",
       "4                         0.313043  ...   \n",
       "...                            ...  ...   \n",
       "85195                     0.474227  ...   \n",
       "85196                     0.474227  ...   \n",
       "85197                     0.472727  ...   \n",
       "85198                     0.474227  ...   \n",
       "85199                     0.474227  ...   \n",
       "\n",
       "       associative_learning_log_p theta = 0.7  \\\n",
       "0                                    1.386294   \n",
       "1                                   -0.000000   \n",
       "2                                   -0.000000   \n",
       "3                                    0.993252   \n",
       "4                                   -0.000000   \n",
       "...                                       ...   \n",
       "85195                                1.098612   \n",
       "85196                                1.098612   \n",
       "85197                                1.324357   \n",
       "85198                                1.098612   \n",
       "85199                                1.098612   \n",
       "\n",
       "       associative_learner_p theta = 0.8  \\\n",
       "0                               0.250000   \n",
       "1                               1.000000   \n",
       "2                               1.000000   \n",
       "3                               0.357143   \n",
       "4                               1.000000   \n",
       "...                                  ...   \n",
       "85195                           0.333331   \n",
       "85196                           0.333331   \n",
       "85197                           0.278809   \n",
       "85198                           0.333332   \n",
       "85199                           0.333338   \n",
       "\n",
       "       associative_learning_log_p theta = 0.8  \\\n",
       "0                                    1.386294   \n",
       "1                                   -0.000000   \n",
       "2                                   -0.000000   \n",
       "3                                    1.029619   \n",
       "4                                   -0.000000   \n",
       "...                                       ...   \n",
       "85195                                1.098618   \n",
       "85196                                1.098620   \n",
       "85197                                1.277229   \n",
       "85198                                1.098617   \n",
       "85199                                1.098598   \n",
       "\n",
       "       associative_learner_p theta = 0.9  \\\n",
       "0                               0.250000   \n",
       "1                               1.000000   \n",
       "2                               1.000000   \n",
       "3                               0.344828   \n",
       "4                               1.000000   \n",
       "...                                  ...   \n",
       "85195                           0.332937   \n",
       "85196                           0.332849   \n",
       "85197                           0.304460   \n",
       "85198                           0.333007   \n",
       "85199                           0.334283   \n",
       "\n",
       "       associative_learning_log_p theta = 0.9  \\\n",
       "0                                    1.386294   \n",
       "1                                   -0.000000   \n",
       "2                                   -0.000000   \n",
       "3                                    1.064711   \n",
       "4                                   -0.000000   \n",
       "...                                       ...   \n",
       "85195                                1.099802   \n",
       "85196                                1.100065   \n",
       "85197                                1.189216   \n",
       "85198                                1.099590   \n",
       "85199                                1.095767   \n",
       "\n",
       "       associative_learner_p theta = 1  associative_learning_log_p theta = 1  \\\n",
       "0                             0.250000                              1.386294   \n",
       "1                             1.000000                             -0.000000   \n",
       "2                             1.000000                             -0.000000   \n",
       "3                             0.333333                              1.098612   \n",
       "4                             1.000000                             -0.000000   \n",
       "...                                ...                                   ...   \n",
       "85195                         0.315436                              1.153799   \n",
       "85196                         0.313333                              1.160488   \n",
       "85197                         0.364341                              1.009665   \n",
       "85198                         0.317881                              1.146079   \n",
       "85199                         0.375000                              0.980829   \n",
       "\n",
       "       seq  cond  subject_rt  \n",
       "0        3     0        1305  \n",
       "1        3     0         431  \n",
       "2        3     0         385  \n",
       "3        4     0         482  \n",
       "4        1     0         321  \n",
       "...    ...   ...         ...  \n",
       "85195    4     2         400  \n",
       "85196    3     2         596  \n",
       "85197    4     2         418  \n",
       "85198    4     2         367  \n",
       "85199    1     2         386  \n",
       "\n",
       "[85200 rows x 39 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a81c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bde1caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in ws: \n",
    "    name = 'rational_chunking_rt w = ' + str(w)            \n",
    "    tempdf = df[(df['cond'] == cond) & (df['subject_rt'] <=1000) & (df['id'] == ID)][name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fef5935c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'rational_chunking_p w = 0.1', 'rational_chunking_rt w = 0.1',\n",
       "       'rational_chunking_p w = 0.2', 'rational_chunking_rt w = 0.2',\n",
       "       'rational_chunking_p w = 0.3', 'rational_chunking_rt w = 0.3',\n",
       "       'rational_chunking_p w = 0.4', 'rational_chunking_rt w = 0.4',\n",
       "       'rational_chunking_p w = 0.5', 'rational_chunking_rt w = 0.5',\n",
       "       'rational_chunking_p w = 0.6', 'rational_chunking_rt w = 0.6',\n",
       "       'parser_log_p forgetting_decrement = 0.03 percept_increment = 0.5',\n",
       "       'parser_log_p forgetting_decrement = 0.03 percept_increment = 1.0',\n",
       "       'parser_log_p forgetting_decrement = 0.03 percept_increment = 1.5',\n",
       "       'parser_log_p forgetting_decrement = 0.04 percept_increment = 0.5',\n",
       "       'parser_log_p forgetting_decrement = 0.04 percept_increment = 1.0',\n",
       "       'parser_log_p forgetting_decrement = 0.04 percept_increment = 1.5',\n",
       "       'parser_log_p forgetting_decrement = 0.05 percept_increment = 0.5',\n",
       "       'parser_log_p forgetting_decrement = 0.05 percept_increment = 1.0',\n",
       "       'parser_log_p forgetting_decrement = 0.05 percept_increment = 1.5',\n",
       "       'parser_log_p forgetting_decrement = 0.06 percept_increment = 0.5',\n",
       "       'parser_log_p forgetting_decrement = 0.06 percept_increment = 1.0',\n",
       "       'parser_log_p forgetting_decrement = 0.06 percept_increment = 1.5',\n",
       "       'parser_log_p forgetting_decrement = 0.07 percept_increment = 0.5',\n",
       "       'parser_log_p forgetting_decrement = 0.07 percept_increment = 1.0',\n",
       "       'parser_log_p forgetting_decrement = 0.07 percept_increment = 1.5',\n",
       "       'associative_learner_p theta = 0.7',\n",
       "       'associative_learning_log_p theta = 0.7',\n",
       "       'associative_learner_p theta = 0.8',\n",
       "       'associative_learning_log_p theta = 0.8',\n",
       "       'associative_learner_p theta = 0.9',\n",
       "       'associative_learning_log_p theta = 0.9',\n",
       "       'associative_learner_p theta = 1',\n",
       "       'associative_learning_log_p theta = 1', 'seq', 'cond', 'subject_rt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd031a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RParsingError",
     "evalue": "Parsing status not OK - PARSING_STATUS.PARSE_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRParsingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a1d3f0274e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i df -o betashcm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"library(lme4)\\nlibrary(lmerTest)\\nm1<-lmer('subject_rt ~ scale(rational_chunking_p w = 0.1) + (scale(rational_chunking_p w = 0.1) |ID)', data=df[!is.infinite(df$rational_chunking_p w = 0.1),])\\nbetashcm<-summary(m1)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0mreturn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0mtext_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m                 \u001b[0mtext_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtext_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;31m# Need the newline in case the last line in code is a comment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"withVisible({%s\\n})\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;31m# Otherwise next return seems to have copy of error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/robjects/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/rinterface_lib/conversion.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cdata_res_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# TODO: test cdata is of the expected CType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cdata_to_rinterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/rinterface.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(text, num)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mrobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStrSexpVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmemorymanagement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrmemory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rinterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__sexp__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rpy2/rinterface_lib/_rinterface_capi.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(cdata, num, rmemory)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;31m# PARSE_EOF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mopenrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARSE_OK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         raise RParsingError('Parsing status not OK',\n\u001b[0m\u001b[1;32m    653\u001b[0m                             status=PARSING_STATUS(status[0]))\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRParsingError\u001b[0m: Parsing status not OK - PARSING_STATUS.PARSE_ERROR"
     ]
    }
   ],
   "source": [
    "%%R -i df -o betashcm\n",
    "\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "m1<-lmer('subject_rt ~ scale(rational_chunking_p w = 0.1) + (scale(rational_chunking_p w = 0.1) |ID)', data=df[!is.infinite(df$rational_chunking_p w = 0.1),])\n",
    "betashcm<-summary(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8c4097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n",
      "lmerModLmerTest]\n",
      "Formula: \"rt ~ scale(lgprational_chunking) + (scale(lgpparser) |ID)\"\n",
      "   Data: dfrt[!is.infinite(dfrt$lgpparser), ]\n",
      "\n",
      "REML criterion at convergence: 955580.2\n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-8.0703 -0.5900 -0.1113  0.4971  6.0332 \n",
      "\n",
      "Random effects:\n",
      " Groups   Name             Variance Std.Dev. Corr \n",
      " ID       (Intercept)      27495.7  165.8         \n",
      "          scale(lgpparser)   265.8   16.3    -0.09\n",
      " Residual                  11507.7  107.3         \n",
      "Number of obs: 78287, groups:  ID, 142\n",
      "\n",
      "Fixed effects:\n",
      "                             Estimate Std. Error        df t value Pr(>|t|)    \n",
      "(Intercept)                 5.513e+02  1.387e+01 1.409e+02   39.76   <2e-16 ***\n",
      "scale(lgprational_chunking) 2.003e+01  5.092e-01 7.592e+04   39.34   <2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr)\n",
      "scl(lgprt_) -0.006\n",
      "[1] 955592.2\n",
      "[1] 955647.8\n"
     ]
    }
   ],
   "source": [
    "%%R -i dfrt -o betashcm\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "m1<-lmer('rt ~ scale(lgprational_chunking) + (scale(lgpparser) |ID)', data=dfrt[!is.infinite(dfrt$lgpparser),])\n",
    "betashcm<-summary(m1)\n",
    "print(summary(m1))\n",
    "#calculate BIC of model1\n",
    "print(AIC(m1))\n",
    "print(BIC(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f212261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n",
      "lmerModLmerTest]\n",
      "Formula: \n",
      "\"rt ~ scale(sim_rt_rational_chunking) + (scale(sim_rt_rational_chunking) |ID)\"\n",
      "   Data: dfrt\n",
      "\n",
      "REML criterion at convergence: 956289.8\n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-8.3969 -0.5885 -0.1082  0.4980  6.2611 \n",
      "\n",
      "Random effects:\n",
      " Groups   Name                            Variance Std.Dev. Corr \n",
      " ID       (Intercept)                     26691.4  163.37        \n",
      "          scale(sim_rt_rational_chunking)   402.4   20.06   -0.24\n",
      " Residual                                 11471.6  107.11        \n",
      "Number of obs: 78366, groups:  ID, 142\n",
      "\n",
      "Fixed effects:\n",
      "                                Estimate Std. Error      df t value Pr(>|t|)\n",
      "(Intercept)                      548.093     13.719 140.882   39.95   <2e-16\n",
      "scale(sim_rt_rational_chunking)   20.328      1.757 141.272   11.57   <2e-16\n",
      "                                   \n",
      "(Intercept)                     ***\n",
      "scale(sim_rt_rational_chunking) ***\n",
      "---\n",
      "Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr)\n",
      "scl(sm_r__) -0.235\n",
      "optimizer (nloptwrap) convergence code: 0 (OK)\n",
      "Model failed to converge with max|grad| = 0.00243828 (tol = 0.002, component 1)\n",
      "\n",
      "[1] 956301.8\n",
      "[1] 956357.4\n"
     ]
    }
   ],
   "source": [
    "%%R -i dfrt -o betashcm\n",
    "library(lme4)\n",
    "library(lmerTest)\n",
    "m1<-lmer('rt ~ scale(sim_rt_rational_chunking) + (scale(sim_rt_rational_chunking) |ID)', data=dfrt)\n",
    "betashcm<-summary(m1)\n",
    "print(summary(m1))\n",
    "#calculate BIC of model1\n",
    "print(AIC(m1))\n",
    "print(BIC(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53f2efe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crational_chunking_mean = 20.32\n",
    "cparser_mean = 10.81\n",
    "\n",
    "# Calculate the standard deviation\n",
    "crationalchunking_stde = 1.76\n",
    "cparser_stde = 1.44\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "\n",
    "# Create lists for the plot\n",
    "Type = ['Our Model','PARSER']\n",
    "x_pos = np.arange(len(Type))\n",
    "CTEs = [crational_chunking_mean,cparser_mean]\n",
    "error = [crationalchunking_stde,cparser_stde]\n",
    "# plt.figure(figsize = (10,5), dpi = 300)\n",
    "# Build the plot\n",
    "fig, ax = plt.subplots(figsize = (3,3), dpi = 300)\n",
    "ax.bar(x_pos, CTEs, yerr=error, align='center', alpha=0.5, ecolor='black',edgecolor = 'k', color = ['gray','gray'], capsize=10)\n",
    "ax.set_title('Standardized Regression Coefficient')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(Type)\n",
    "#ax.yaxis.grid(True)\n",
    "\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ec453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
